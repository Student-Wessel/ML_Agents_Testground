{
    "name": "root",
    "gauges": {
        "RaceAgent.Policy.Entropy.mean": {
            "value": 0.7496410608291626,
            "min": 0.737837553024292,
            "max": 1.0527437925338745,
            "count": 149
        },
        "RaceAgent.Policy.Entropy.sum": {
            "value": 22301.822265625,
            "min": 21996.919921875,
            "max": 30982.25,
            "count": 149
        },
        "RaceAgent.Step.mean": {
            "value": 11639988.0,
            "min": 7199900.0,
            "max": 11639988.0,
            "count": 149
        },
        "RaceAgent.Step.sum": {
            "value": 11639988.0,
            "min": 7199900.0,
            "max": 11639988.0,
            "count": 149
        },
        "RaceAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.45020899176597595,
            "min": 0.3169061541557312,
            "max": 0.4544822871685028,
            "count": 149
        },
        "RaceAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 108.5003662109375,
            "min": 75.74057006835938,
            "max": 109.53022766113281,
            "count": 149
        },
        "RaceAgent.Policy.CuriosityValueEstimate.mean": {
            "value": 0.001060390379279852,
            "min": 0.0006641864310950041,
            "max": 0.007486375048756599,
            "count": 149
        },
        "RaceAgent.Policy.CuriosityValueEstimate.sum": {
            "value": 0.25555408000946045,
            "min": 0.15940473973751068,
            "max": 1.8042163848876953,
            "count": 149
        },
        "RaceAgent.Losses.PolicyLoss.mean": {
            "value": 0.06898638607352656,
            "min": 0.06301925594877932,
            "max": 0.0727153378545507,
            "count": 149
        },
        "RaceAgent.Losses.PolicyLoss.sum": {
            "value": 0.8278366328823187,
            "min": 0.6866733781956433,
            "max": 0.8645272931453609,
            "count": 149
        },
        "RaceAgent.Losses.ValueLoss.mean": {
            "value": 8.480434955860017e-05,
            "min": 6.796746351387441e-05,
            "max": 0.0006425607790186491,
            "count": 149
        },
        "RaceAgent.Losses.ValueLoss.sum": {
            "value": 0.001017652194703202,
            "min": 0.0007476420986526186,
            "max": 0.006425607790186491,
            "count": 149
        },
        "RaceAgent.Policy.LearningRate.mean": {
            "value": 8.374653460356665e-06,
            "min": 8.374653460356665e-06,
            "max": 1.2813056434897504e-05,
            "count": 149
        },
        "RaceAgent.Policy.LearningRate.sum": {
            "value": 0.00010049584152427998,
            "min": 9.245444973094002e-05,
            "max": 0.0001527059964722,
            "count": 149
        },
        "RaceAgent.Policy.Epsilon.mean": {
            "value": 0.14187297666666662,
            "min": 0.14187297666666662,
            "max": 0.1640651025,
            "count": 149
        },
        "RaceAgent.Policy.Epsilon.sum": {
            "value": 1.7024757199999996,
            "min": 1.5622690600000002,
            "max": 1.9635278,
            "count": 149
        },
        "RaceAgent.Policy.Beta.mean": {
            "value": 0.004193110369000001,
            "min": 0.004193110369000001,
            "max": 0.00641010373975,
            "count": 149
        },
        "RaceAgent.Policy.Beta.sum": {
            "value": 0.05031732442800001,
            "min": 0.046290679093999997,
            "max": 0.07639642722,
            "count": 149
        },
        "RaceAgent.Losses.CuriosityForwardLoss.mean": {
            "value": 0.017691561272558783,
            "min": 0.01587824134057331,
            "max": 0.10977813255603588,
            "count": 149
        },
        "RaceAgent.Losses.CuriosityForwardLoss.sum": {
            "value": 0.2122987352707054,
            "min": 0.17466065474630643,
            "max": 1.0977813255603588,
            "count": 149
        },
        "RaceAgent.Losses.CuriosityInverseLoss.mean": {
            "value": 0.09511692207799388,
            "min": 0.08770083106817707,
            "max": 0.25589616756945377,
            "count": 149
        },
        "RaceAgent.Losses.CuriosityInverseLoss.sum": {
            "value": 1.1414030649359266,
            "min": 0.9647091417499477,
            "max": 2.5589616756945377,
            "count": 149
        },
        "RaceAgent.Environment.EpisodeLength.mean": {
            "value": 4999.0,
            "min": 718.8214285714286,
            "max": 4999.0,
            "count": 149
        },
        "RaceAgent.Environment.EpisodeLength.sum": {
            "value": 34993.0,
            "min": 9302.0,
            "max": 45263.0,
            "count": 149
        },
        "RaceAgent.Environment.CumulativeReward.mean": {
            "value": 22.553445155599288,
            "min": 2.240609285014216,
            "max": 22.577070984989405,
            "count": 149
        },
        "RaceAgent.Environment.CumulativeReward.sum": {
            "value": 157.874116089195,
            "min": 34.900547655299306,
            "max": 184.25681510893628,
            "count": 149
        },
        "RaceAgent.Policy.ExtrinsicReward.mean": {
            "value": 22.553445155599288,
            "min": 2.240609285014216,
            "max": 22.577070984989405,
            "count": 149
        },
        "RaceAgent.Policy.ExtrinsicReward.sum": {
            "value": 157.874116089195,
            "min": 34.900547655299306,
            "max": 184.25681510893628,
            "count": 149
        },
        "RaceAgent.Policy.CuriosityReward.mean": {
            "value": 0.47212962880231707,
            "min": 0.38719838386168703,
            "max": 1.316522401815746,
            "count": 149
        },
        "RaceAgent.Policy.CuriosityReward.sum": {
            "value": 3.3049074016162194,
            "min": 1.5276546120876446,
            "max": 14.778704979689792,
            "count": 149
        },
        "RaceAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 149
        },
        "RaceAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 149
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1654787461",
        "python_version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Wessel\\Documents\\School\\Personal Portofolio\\AI\\ML_Agents_Testground\\venv\\Scripts\\mlagents-learn config/RaceAgentV3.yaml --run-id=RaceAgentV8 --resume",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.22.2",
        "end_time_seconds": "1654792716"
    },
    "total": 5255.144896,
    "count": 1,
    "self": 0.004302800000004936,
    "children": {
        "run_training.setup": {
            "total": 0.06937459999999995,
            "count": 1,
            "self": 0.06937459999999995
        },
        "TrainerController.start_learning": {
            "total": 5255.0712186,
            "count": 1,
            "self": 5.373738599725584,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.8306004,
                    "count": 1,
                    "self": 7.8306004
                },
                "TrainerController.advance": {
                    "total": 5241.8034632002755,
                    "count": 448672,
                    "self": 5.089694300336305,
                    "children": {
                        "env_step": {
                            "total": 2964.7761659998414,
                            "count": 448672,
                            "self": 2077.871240299476,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 883.4070986001013,
                                    "count": 448672,
                                    "self": 16.90503909993606,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 866.5020595001653,
                                            "count": 448034,
                                            "self": 250.99721490008403,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 615.5048446000812,
                                                    "count": 448034,
                                                    "self": 615.5048446000812
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 3.4978271002638106,
                                    "count": 448671,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 5178.613860800105,
                                            "count": 448671,
                                            "is_parallel": true,
                                            "self": 3492.8994253001742,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00046560000000006596,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0001886999999989314,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00027690000000113457,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00027690000000113457
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1685.7139698999304,
                                                    "count": 448671,
                                                    "is_parallel": true,
                                                    "self": 45.01092660001109,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 50.85116510001126,
                                                            "count": 448671,
                                                            "is_parallel": true,
                                                            "self": 50.85116510001126
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1453.48596239992,
                                                            "count": 448671,
                                                            "is_parallel": true,
                                                            "self": 1453.48596239992
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 136.365915799988,
                                                            "count": 448671,
                                                            "is_parallel": true,
                                                            "self": 57.36801399997226,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 78.99790180001573,
                                                                    "count": 1794684,
                                                                    "is_parallel": true,
                                                                    "self": 78.99790180001573
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2271.9376029000978,
                            "count": 448671,
                            "self": 9.63594440019915,
                            "children": {
                                "process_trajectory": {
                                    "total": 276.96442109990073,
                                    "count": 448671,
                                    "self": 276.51384619990034,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.45057490000039024,
                                            "count": 9,
                                            "self": 0.45057490000039024
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1985.3372373999978,
                                    "count": 1694,
                                    "self": 508.7949295999431,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 1476.5423078000547,
                                            "count": 104661,
                                            "self": 1476.5423078000547
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.06341639999936888,
                    "count": 1,
                    "self": 0.007856499999434163,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.055559899999934714,
                            "count": 1,
                            "self": 0.055559899999934714
                        }
                    }
                }
            }
        }
    }
}